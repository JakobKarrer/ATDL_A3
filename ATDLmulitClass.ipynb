{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ylLu6OsUc_17"
      },
      "outputs": [],
      "source": [
        "!pip install torchxrayvision\n",
        "!pip install timm\n",
        "!pip install torchmetrics\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip OCT2017.zip"
      ],
      "metadata": {
        "id": "8tRAJ7ToBpF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import glob\n",
        "#len(glob.glob(\"OCT2017/train/DME/*\"))"
      ],
      "metadata": {
        "id": "UVFxleaVGX4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU37oedTcrVB"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import cv2\n",
        "import timm\n",
        "from timm.models.vision_transformer import VisionTransformer as timm_ViT\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from einops import rearrange\n",
        "from safetensors import safe_open\n",
        "from safetensors.torch import save_file\n",
        "import torchxrayvision as xrv\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W71TIQyVuI8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "!unzip /content/drive/MyDrive/ATDL5/OCT2017.zip -d /content/\n",
        "#!rm -r OCT2017/train/sample_data/"
      ],
      "metadata": {
        "id": "nDTnWjGHKx87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "len(glob.glob(\"/content/OCT2017/train/CNV/*\"))\n",
        "#len(glob.glob(\"/content/drive/MyDrive/ATDL5/OCT2017/train/TESTCNV/CNV/*\"))"
      ],
      "metadata": {
        "id": "OuGmP0WbS-AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ATDL5/trainoct2.csv /content/trainoct2.csv\n"
      ],
      "metadata": {
        "id": "rnW9hPZLdD8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPNytpISczW3"
      },
      "outputs": [],
      "source": [
        "\n",
        "#%cd drive/MyDrive/ATDL5\n",
        "timse = time.time()\n",
        "# #!mkdir OCT2017/train\n",
        "# !cp -r /content/drive/MyDrive/ATDL5/OCT2017/train/CNV /content/OCT2017/train/\n",
        "# !cp -r /content/drive/MyDrive/ATDL5/OCT2017/train/NORMAL /content/OCT2017/train/\n",
        "# !cp -r /content/drive/MyDrive/ATDL5/OCT2017/train/DME /content/OCT2017/train/\n",
        "# !cp -r /content/drive/MyDrive/ATDL5/OCT2017/train/CNV /content/OCT2017/train/\n",
        "\n",
        "\n",
        "timse = time.time() - timse\n",
        "print(timse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "147.93058276176453"
      ],
      "metadata": {
        "id": "i6vB2XHuNWmM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPIml0sZdXYo"
      },
      "outputs": [],
      "source": [
        "#@title LoraLayer\n",
        "class _LoRALayer(nn.Module):\n",
        "    def __init__(self, w: nn.Module, w_a_q: nn.Module, w_b_q: nn.Module,\n",
        "                                 w_a_v: nn.Module, w_b_v: nn.Module, r: int, alpha: int, dim:int):\n",
        "        super().__init__()\n",
        "        self.w = w\n",
        "\n",
        "        self.w_a_q = w_a_q\n",
        "        self.w_b_q = w_b_q\n",
        "\n",
        "        self.w_a_v = w_a_v\n",
        "        self.w_b_v = w_b_v\n",
        "\n",
        "        self.r = r\n",
        "        self.alpha = alpha\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        val = self.w(x)\n",
        "        val[:,:,:self.dim] += (self.alpha // self.r) * self.w_b_q(self.w_a_q(x))\n",
        "        val[:,:,self.dim*2:] += (self.alpha // self.r) * self.w_b_v(self.w_a_v(x))\n",
        "        return val\n",
        "class LoRA_ViT(nn.Module):\n",
        "    def __init__(self, vit_model, r: int, alpha: int, num_classes: int = 0, lora_layer=None):\n",
        "        super(LoRA_ViT, self).__init__()\n",
        "\n",
        "        base_vit_dim = vit_model.blocks[0].attn.qkv.in_features\n",
        "        dim = base_vit_dim\n",
        "        if lora_layer:\n",
        "            self.lora_layer = lora_layer\n",
        "        else:\n",
        "            self.lora_layer = list(range(len(vit_model.blocks)))\n",
        "\n",
        "        self.w_As = nn.ModuleList()\n",
        "        self.w_Bs = nn.ModuleList()\n",
        "\n",
        "\n",
        "        for param in vit_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for t_layer_i, blk in enumerate(vit_model.blocks):\n",
        "\n",
        "            if t_layer_i not in self.lora_layer:\n",
        "                continue\n",
        "            #w_q_linear = blk.attn.proj_q\n",
        "            #w_v_linear = blk.attn.proj_v\n",
        "            w_qkv_linear = blk.attn.qkv\n",
        "\n",
        "            w_a_linear_q = nn.Linear(dim, r, bias=False)\n",
        "            w_b_linear_q = nn.Linear(r, dim, bias=False)\n",
        "\n",
        "\n",
        "            w_a_linear_v = nn.Linear(dim, r, bias=False)\n",
        "            w_b_linear_v = nn.Linear(r, dim, bias=False)\n",
        "\n",
        "\n",
        "            self.w_As.append(w_a_linear_q)\n",
        "            self.w_Bs.append(w_b_linear_q)\n",
        "            self.w_As.append(w_a_linear_v)\n",
        "            self.w_Bs.append(w_b_linear_v)\n",
        "\n",
        "            blk.attn.qkv = _LoRALayer(w_qkv_linear, w_a_linear_q, w_b_linear_q, w_a_linear_v, w_b_linear_v,r, alpha, dim)\n",
        "\n",
        "        self.reset_parameters()\n",
        "        self.lora_vit = vit_model\n",
        "    def save_fc_parameters(self, filename: str) -> None:\n",
        "        assert filename.endswith(\".safetensors\")\n",
        "        _in = self.lora_vit.fc.in_features\n",
        "        _out = self.lora_vit.fc.out_features\n",
        "        fc_tensors = {f\"fc_{_in}in_{_out}out\": self.lora_vit.fc.weight}\n",
        "        save_file(fc_tensors, filename)\n",
        "    def reset_parameters(self) -> None:\n",
        "        for w_A in self.w_As:\n",
        "            nn.init.kaiming_uniform_(w_A.weight, a=math.sqrt(5))\n",
        "        for w_B in self.w_Bs:\n",
        "            nn.init.zeros_(w_B.weight)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.lora_vit(x)\n",
        "    def get_intermediate_layers(self, x: torch.Tensor, n,  reshape = False, return_class_token= False,norm=True):\n",
        "        return self.lora_vit.get_intermediate_layers(x, n, reshape, return_class_token, norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm8FNgF8eNCK"
      },
      "outputs": [],
      "source": [
        "#@title Transformer\n",
        "\n",
        "transform_toTensor = transforms.Lambda(lambda x: torch.tensor(np.array(x), dtype=torch.uint8).unsqueeze(0))\n",
        "#to_rgb = transforms.Lambda(lambda x: np.stack([x] * 3, axis=-1))\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "  #  to_rgb,\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomResizedCrop(size = (224,224), scale=(0.2, 1)),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    #transforms.Normalize(mean=[0.4823, 0.4823, 0.4823],std = [0.2232, 0.2232, 0.2232]),\n",
        "    #transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],std = [0.1953, 0.1925, 0.1942]),\n",
        "    #\n",
        "])\n",
        "transform_train_mask = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((32, 32),interpolation=InterpolationMode.NEAREST_EXACT),\n",
        "])\n",
        "\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomResizedCrop(size =(224,224), scale=(0.2, 1)),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    #transforms.Normalize(mean=[0.4823, 0.4823, 0.4823],std = [0.2232, 0.2232, 0.2232]),\n",
        "    #transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],std = [0.1953, 0.1925, 0.1942])\n",
        "])\n",
        "transform_val_mask = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224), interpolation=InterpolationMode.NEAREST_EXACT),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqaJdvTNffLL"
      },
      "outputs": [],
      "source": [
        "#@title Dataset\n",
        "# print(\"Path to dataset files:\", path)\n",
        "path = \"\"\n",
        "\n",
        "#Source: https://www.kaggle.com/code/akshar1812/lung-segmentation\n",
        "class LungSegmentationDataset(Dataset):\n",
        "    def __init__(self, df=None, base_dir=None, resize=None, transform=None, target_transform=None, both_transform=None):\n",
        "        self.data = df\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.resize = resize\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.both_transform=both_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_relative_path = self.data.iloc[idx, 0]#0\n",
        "        label = self.data.iloc[idx, 1]#1\n",
        "        img_path = self.base_dir / img_relative_path\n",
        "        # Load image and mask using OpenCV\n",
        "        image = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found at path: {img_path}\")\n",
        "        #print(image.shape)\n",
        "        image = np.stack([image] * 3, axis=-1)#fjern\n",
        "        #print(image.shape)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        #print(torch.unique(mask))\n",
        "        #mask = mask.long()\n",
        "        #print(\"image\")\n",
        "        return image, label\n",
        "\n",
        "#\n",
        "#image = torch.from_numpy(image).permute(2,0,1).float()\n",
        "#num_classes\n",
        "df_data = pd.read_csv(\"trainoct2.csv\")\n",
        "\n",
        "train_df, val_df = train_test_split(df_data, test_size=0.2, random_state=42) #THE ANSWER TO THE QUESTION\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0enoFylfg3x"
      },
      "outputs": [],
      "source": [
        "#@title Training Parameters\n",
        "models = [] #Dino Frozen, DinoLora\n",
        "rs =  [0,10,225]#255, 0, 1, 3, 5, 10, 20] #255 being a dummy class for the full optimization no LORA\n",
        "num_classes = 4\n",
        "learning_rate = 1e-2\n",
        "num_epochs = 10\n",
        "batch_size=32\n",
        "num_layers = 1\n",
        "input_dim = 384*num_layers\n",
        "weight_decay = 1e-3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_dataset = LungSegmentationDataset(df=train_df, base_dir=path, resize=448,\n",
        "                                                    transform=transform_train, target_transform=transform_train_mask)\n",
        "\n",
        "val_dataset = LungSegmentationDataset(df=val_df, base_dir=path, resize=448,\n",
        "                                      transform=transform_val, target_transform=transform_val_mask)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fInijOdWfkTc"
      },
      "outputs": [],
      "source": [
        "#@title LinearHead\n",
        "\n",
        "class LinearHead(nn.Module):\n",
        "    def __init__(self, dino, r ,in_features=1920, out_features=4, bias=True):\n",
        "        super(LinearHead, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias)\n",
        "        if r == 0:\n",
        "            for param in dino.parameters():\n",
        "                param.requires_grad = False\n",
        "            self.lora_dino = dino\n",
        "        elif r == 255:\n",
        "            self.lora_dino = dino\n",
        "        else:\n",
        "            self.lora_dino = LoRA_ViT(dino, r=r, alpha=8, num_classes=0)\n",
        "\n",
        "    def forward(self, imgs, num_layers):\n",
        "        feature = self.lora_dino.get_intermediate_layers(imgs, num_layers, return_class_token=True)\n",
        "        feature = feature[0][0][:, 0]#####\n",
        "        outputs = []\n",
        "        outputs = self.linear(feature)\n",
        "        #outputs = torch.stack(outputs, dim=1)\n",
        "        return outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = cv2.imread(\"2OCT2017/train/NORMAL/NORMAL-9651399-4.jpeg\")\n",
        "print(a)"
      ],
      "metadata": {
        "id": "ex_ohnwcb1_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7O-y3A9fn3r"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "import tqdm\n",
        "from torchmetrics import StatScores\n",
        "df = pd.DataFrame(columns=[\"r\", \"loss\", \"dice_metric\", \"trainloss\",\"trainable\", \"best_model\", \"time\"])\n",
        "for r in rs:\n",
        "    dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "    model = LinearHead(dinov2_vits14, r, input_dim, num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #criterion = nn.CrossEntropyLoss(weight =torch.tensor([0.25783639143730885, 0.7421636085626911]).to(device))\n",
        "    #criterion = CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(filter(lambda a : a.requires_grad, model.parameters()), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs*len(train_loader.dataset), eta_min=0.0001)\n",
        "    Ss = StatScores(task=\"multiclass\", num_classes=4 ,average='micro').to(device)\n",
        "\n",
        "    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(\"trainable parameters\", num_trainable_params)\n",
        "    iteration = {\"r\": r, \"loss\": [], \"dice_metric\": [], \"trainloss\": [],\"trainable\":num_trainable_params , \"best_model\": None, \"time\":None}\n",
        "\n",
        "    dice_metric_max = 0\n",
        "    start = time.time()\n",
        "    val_metric_max =0\n",
        "    print(num_epochs)\n",
        "    itpertrain = len(train_loader)\n",
        "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "\n",
        "        print(\"Current Epoch: \", epoch)\n",
        "        model.train()\n",
        "        running_lorunning_loss = 0\n",
        "        losscomp = 0\n",
        "        for i, (imgs, labels) in enumerate(train_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(imgs, num_layers)\n",
        "            loss = criterion(outputs, labels)\n",
        "            losscomp += loss.item()\n",
        "            outputs = torch.argmax(outputs, dim=1).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_ss = Ss([0,1,2,3], [0,1,2,3]).to(device)\n",
        "        with torch.no_grad():\n",
        "            for i, (imgs, label) in enumerate(val_loader):\n",
        "                imgs = imgs.to(device)\n",
        "                label = label.to(device)\n",
        "                outputs = model(imgs, num_layers)\n",
        "                loss = criterion(outputs, label)\n",
        "                val_loss += loss.item()\n",
        "                preds = torch.argmax(outputs, dim=1).to(device)\n",
        "                val_ss += Ss(preds, label).to(device)\n",
        "                #print(val_ss)\n",
        "                #patch_labels = patch_labels.view(-1, int(np.sqrt(feature[0][0].shape[1])), int(np.sqrt(feature[0][0].shape[1])))\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "            print(\"Average Loss: \", avg_val_loss)\n",
        "            if avg_val_loss > val_metric_max:\n",
        "                val_metric_max = avg_val_loss\n",
        "                iteration[\"best_model\"] = model\n",
        "            iteration[\"loss\"].append(avg_val_loss)\n",
        "            iteration[\"dice_metric\"].append(val_ss)#ss\n",
        "            iteration[\"trainloss\"].append(losscomp/itpertrain)\n",
        "            print(val_ss)\n",
        "    end = time.time()\n",
        "    length = end - start\n",
        "    iteration[\"time\"] = length\n",
        "    iteration_df = pd.DataFrame([iteration])\n",
        "    df = pd.concat([df, iteration_df], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyLOshHBsTt8"
      },
      "outputs": [],
      "source": [
        "iteration[\"best_model\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXZ2q6JVZ3bR"
      },
      "outputs": [],
      "source": [
        "#r0 = df[df[\"r\"]==0]185090 for 10\n",
        "#torch.save(r0[\"best_model\"][0].state_dict(), \"r01.pt\")\n",
        "r0 = df[df[\"r\"]==255]\n",
        "torch.save(iteration[\"best_model\"], \"r0255.pt\")\n",
        "#r0 = df[df[\"r\"]==255]\n",
        "#torch.save(r0[\"best_model\"][0].state_dict(), \"r0255.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR8NsUUgMX7n"
      },
      "outputs": [],
      "source": [
        "# for epoch in range(2):\n",
        "\n",
        "#         print(\"Current Epoch: \", epoch)\n",
        "#         model.train()\n",
        "#         running_lorunning_lossss = 0.0\n",
        "#         for i, (imgs, labels) in enumerate(train_loader):\n",
        "#             imgs = imgs.to(device)\n",
        "#             #print(imgs.shape)\n",
        "#             labels = labels.to(device)\n",
        "#             outputs = model(imgs, num_layers)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             outputs = torch.argmax(outputs, dim=1).to(device)\n",
        "#             #print(Ss(outputs, labels))\n",
        "#             #print(Ss(outputs, labels))\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             scheduler.step()\n",
        "\n",
        "#         model.eval()\n",
        "#         val_loss = 0.0\n",
        "#         val_ss = torch.tensor([0,0,0,0,0]).to(device)\n",
        "#         with torch.no_grad():\n",
        "#             for i, (imgs, label) in enumerate(val_loader):\n",
        "#                 imgs = imgs.to(device)\n",
        "#                 label = label.to(device)\n",
        "\n",
        "#                 outputs = model(imgs, num_layers)\n",
        "\n",
        "#                 loss = criterion(outputs, label)\n",
        "#                 val_loss += loss.item()\n",
        "\n",
        "\n",
        "#                 preds = torch.argmax(outputs, dim=1).to(device)\n",
        "#                 val_ss += Ss(preds, label).to(device)\n",
        "#                 #print(val_ss)\n",
        "#                 #patch_labels = patch_labels.view(-1, int(np.sqrt(feature[0][0].shape[1])), int(np.sqrt(feature[0][0].shape[1])))\n",
        "#             avg_val_loss = val_loss / len(val_loader)\n",
        "#             print(\"Average Loss: \", avg_val_loss)\n",
        "#             if avg_val_loss > val_metric_max:\n",
        "#                 val_metric_max = avg_val_loss\n",
        "#                 iteration[\"best_model\"] = model\n",
        "#             iteration[\"loss\"].append(avg_val_loss)\n",
        "#             iteration[\"dice_metric\"].append(val_ss)#ss\n",
        "#             print(val_ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcsXVibSoieK"
      },
      "source": [
        "sing cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n",
        "r\n",
        "trainable parameters 56066\n",
        "Current Epoch:  0\n",
        "Average Loss:  0.5955867114843745\n",
        "tensor([761, 286,   0,   0, 761], device='cuda:0')\n",
        "Current Epoch:  1\n",
        "Average Loss:  0.6074274760304075\n",
        "tensor([761, 286,   0,   0, 761], device='cuda:0')\n",
        "Current Epoch:  2\n",
        "Average Loss:  0.4687202807628747\n",
        "tensor([725, 200,  86,  36, 761], device='cuda:0')\n",
        "Current Epoch:  3\n",
        "Average Loss:  0.451808985830708\n",
        "tensor([755, 241,  45,   6, 761], device='cuda:0')\n",
        "Current Epoch:  4\n",
        "Average Loss:  0.385383073127631\n",
        "tensor([673,  74, 212,  88, 761], device='cuda:0')\n",
        "Current Epoch:  5\n",
        "Average Loss:  0.3380863786195264\n",
        "tensor([649,  30, 256, 112, 761], device='cuda:0')\n",
        "Current Epoch:  6\n",
        "Average Loss:  0.3001688461412083\n",
        "tensor([700,  74, 212,  61, 761], device='cuda:0')\n",
        "Current Epoch:  7\n",
        "Average Loss:  0.4694155455764496\n",
        "tensor([749, 200,  86,  12, 761], device='cuda:0')\n",
        "Current Epoch:  8\n",
        "Average Loss:  0.3109981073348811\n",
        "tensor([662,  25, 261,  99, 761], device='cuda:0')\n",
        "Current Epoch:  9\n",
        "Average Loss:  0.23698267735766643\n",
        "tensor([700,  36, 250,  61, 761], device='cuda:0')\n",
        "\n",
        "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n",
        "\n",
        "trainable parameters 22057346\n",
        "Current Epoch:  0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glPyONdilkFK"
      },
      "outputs": [],
      "source": [
        "# #@title Training\n",
        "# from torchmetrics import StatScores\n",
        "# df = pd.DataFrame(columns=[\"r\", \"loss\", \"dice_metric\", \"trainable\", \"best_model\", \"time\"])\n",
        "# for r in rs:\n",
        "#     dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "#     model = LinearHead(dinov2_vits14, r, input_dim, num_classes).to(device)\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     #criterion = CrossEntropyLoss()\n",
        "#     optimizer = optim.AdamW(filter(lambda a : a.requires_grad, model.parameters()), lr=learning_rate)\n",
        "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs*len(train_loader.dataset), eta_min=0.0001)\n",
        "#     Ss = StatScores(task=\"Binary\", average='micro').to(device)\n",
        "\n",
        "#     num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "#     print(\"trainable parameters\", num_trainable_params)\n",
        "#     iteration = {\"r\": r, \"loss\": [], \"dice_metric\": [], \"trainable\":num_trainable_params , \"best_model\": None, \"time\":None}\n",
        "\n",
        "#     dice_metric_max = 0\n",
        "#     start = time.time()\n",
        "#     val_metric_max =0\n",
        "#     for epoch in range(num_epochs):\n",
        "\n",
        "#         print(\"Current Epoch: \", epoch)\n",
        "#         model.train()\n",
        "#         running_lorunning_lossss = 0.0\n",
        "#         for i, (imgs, labels) in enumerate(train_loader):\n",
        "#             imgs = imgs.to(device)\n",
        "#             #print(imgs.shape)\n",
        "#             labels = labels.to(device)\n",
        "#             outputs = model(imgs, num_layers)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             outputs = torch.argmax(outputs, dim=1).to(device)\n",
        "#             #print(Ss(outputs, labels))\n",
        "#             #print(Ss(outputs, labels))\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             scheduler.step()\n",
        "\n",
        "#         model.eval()\n",
        "#         val_loss = 0.0\n",
        "#         val_ss = torch.tensor([0,0,0,0,0]).to(device)\n",
        "#         with torch.no_grad():\n",
        "#             for i, (imgs, label) in enumerate(val_loader):\n",
        "#                 imgs = imgs.to(device)\n",
        "#                 label = label.to(device)\n",
        "\n",
        "#                 outputs = model(imgs, num_layers)\n",
        "\n",
        "#                 loss = criterion(outputs, label)\n",
        "#                 val_loss += loss.item()\n",
        "\n",
        "\n",
        "#                 preds = torch.argmax(outputs, dim=1).to(device)\n",
        "#                 val_ss += Ss(preds, label).to(device)\n",
        "#                 #print(val_ss)\n",
        "#                 #patch_labels = patch_labels.view(-1, int(np.sqrt(feature[0][0].shape[1])), int(np.sqrt(feature[0][0].shape[1])))\n",
        "#             avg_val_loss = val_loss / len(val_loader)\n",
        "#             print(\"Average Loss: \", avg_val_loss)\n",
        "#             if avg_val_loss > val_metric_max:\n",
        "#                 val_metric_max = avg_val_loss\n",
        "#                 iteration[\"best_model\"] = model\n",
        "#             iteration[\"loss\"].append(avg_val_loss)\n",
        "#             iteration[\"dice_metric\"].append(val_ss)#ss\n",
        "#             print(val_ss)\n",
        "#     end = time.time()\n",
        "#     length = end - start\n",
        "#     iteration[\"time\"] = length\n",
        "#     iteration_df = pd.DataFrame([iteration])\n",
        "#     df = pd.concat([df, iteration_df], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2fmj6ABh_Vc"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzFkNqbTau-g"
      },
      "outputs": [],
      "source": [
        "# #@title Time\n",
        "# from torchmetrics import StatScores\n",
        "# df = pd.DataFrame(columns=[\"r\", \"time\"])\n",
        "# rs = [0]\n",
        "# for r in rs:\n",
        "#     dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "#     model = LinearHead(dinov2_vits14, r, input_dim, num_classes).to(device)\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     #criterion = CrossEntropyLoss()\n",
        "#     optimizer = optim.AdamW(filter(lambda a : a.requires_grad, model.parameters()), lr=learning_rate)\n",
        "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs*len(train_loader.dataset), eta_min=0.0001)\n",
        "#     Ss = StatScores(task=\"Binary\", average='micro').to(device)\n",
        "\n",
        "#     num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "#     print(\"trainable parameters\", num_trainable_params)\n",
        "#     iteration = {\"r\": r,\"time\":None}\n",
        "\n",
        "#     dice_metric_max = 0\n",
        "#     start = time.time()\n",
        "#     val_metric_max =0\n",
        "#     for epoch in range(num_epochs):\n",
        "\n",
        "#         print(\"Current Epoch: \", epoch)\n",
        "#         model.train()\n",
        "#         running_lorunning_lossss = 0.0\n",
        "#         for i, (imgs, labels) in enumerate(train_loader):\n",
        "#             imgs = imgs.to(device)\n",
        "#             #print(imgs.shape)\n",
        "#             labels = labels.to(device)\n",
        "#             outputs = model(imgs, num_layers)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             outputs = torch.argmax(outputs, dim=1).to(device)\n",
        "#             #print(Ss(outputs, labels))\n",
        "#             #print(Ss(outputs, labels))\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             scheduler.step()\n",
        "#     end = time.time()\n",
        "#     length = end - start\n",
        "#     iteration[\"r\"] = r\n",
        "#     iteration[\"time\"] = length\n",
        "#     iteration_df = pd.DataFrame([iteration])\n",
        "#     df = pd.concat([df, iteration_df], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9q53BXu4CV8"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We0Qz5Ktsdl0"
      },
      "outputs": [],
      "source": [
        "#[tp, fp, tn, fn, sup]\n",
        "#idx r \ttime\n",
        "#0 \t3 \t3289.828014\n",
        "#1 \t255 3470.051729\n",
        "#2  0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMdT2rMbTdgw"
      },
      "outputs": [],
      "source": [
        "time.sleep(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tSnxATcTNjJ"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "time.sleep(10)\n",
        "end = time.time()\n",
        "print(end-start)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}